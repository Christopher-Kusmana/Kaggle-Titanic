{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa02bc-4e8b-471f-8cf1-27c7a1732edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c0bfe1-6ed3-4d84-b7b6-e41f7a7c896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe is a 2D array contaning row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2cf8e0-22b1-4b04-967f-7db330ec89d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/survey_results_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c1a4dbb-861c-41f1-9c89-a762a08f51e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = pd.read_csv('data/survey_results_schema.csv', index_col='Column' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d070f84b-ac38-4659-9959-f415526241e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape prints out the dimesion of the dataframe (row, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4f3b73-964e-4f86-be7b-4a0224df893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info() prints out the info of columns and rows and the columns' data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91af1dd3-0471-4e3f-b80c-474764334da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 85) #tweaks the option of max columns being printed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2154e779-3dc2-4561-a97f-696ac7911e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 85) #tweaks the option of max columns being printed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78534103-90b1-49ff-b65a-127dded05c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head(x) prints the first x row, default is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e72592d-c153-4ae2-a790-3b0f66666e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail(x) prints the last x row, default is 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2888daed-1fe5-469c-8a88-aa072e7f1e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = {\n",
    "    \"first\" : [\"Christopher\", \"Cherryl\", \"Mei\", \"Finn\", \"Iurii\", \"Eric\", \"Isidor\"],\n",
    "    \"last\"  : [\"Kusmana\", \"Soputan\", \"Imaizumi\", \"Hansen\", \"Onopko\", \"Cao\", \"Manning\"],\n",
    "    \"age\"   : [19, 18, 22, 22, 18, 18, 19],\n",
    "    \"gender\" : [\"M\", \"F\", \"F\", \"M\", \"M\", \"M\", \"M\"]\n",
    "} # Creates dictionary of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6f86f80-61a7-4ed6-bf89-27b2fc341336",
   "metadata": {},
   "outputs": [],
   "source": [
    "people_df = pd.DataFrame(people) # Create a tabular dataframe given a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24734a95-5ae5-4559-b3bc-3f6740079657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMN ACCESS (bracket notations and parameters)\n",
    "\n",
    "#people_df[x][y] access specific key of a dictionary given x and y; \n",
    "#but it can also print out a whol column if y is not specified for instance people_df['age'] prints out the age column\n",
    "\n",
    "# Dot notation is also possible: people_df.first but bracket is more conventional\n",
    "\n",
    "# To access multiple columns, pass in x as a list of keys; people_df[['first', 'last']]\n",
    "\n",
    "# To access the columns keys, use people_df.columns respectively as a built in dataframe method\n",
    "\n",
    "# ROW ACCESS (iloc and loc)\n",
    "\n",
    "# To access dataframe by row, use iloc[] (index locator); people_df.iloc[x]\n",
    "\n",
    "# To access multiple row, pass in a list for the accessor x in iloc[x]; people_df.iloc[[0,2]] prints out row 1 and 3 of the table\n",
    "\n",
    "# You can access a second parameter for iloc to index specific column(s), can also be passed as a list\n",
    "\n",
    "# Just like iloc, loc works the same but only differs in the second parameter, it takes the key (label) of the column instead of index; people_df.loc[[2,4], ['last', 'age']] \n",
    "\n",
    "# You can use list slicing to grab row/columns index i to j; people_df.loc[0:2, 'first' : 'age'] \n",
    "\n",
    "# First param in the loc is the row that you want and the second param is the column that you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e4a426e-5a61-4f8d-8090-6a0d5f0ecbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_counts() is a method that counts the frequency of values/responses in given column; people_df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c18dac3-dfaf-4b2c-9863-599e1cf55d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDICES / INDEX\n",
    "\n",
    "# set_index(i) function remaps the index to the given parameter (as an instance not reference if inplace is not specified); people_df.set_index('last', inplace=True) permanently remaps the index to last names\n",
    "# reset_index(inplace=True) modifies the index to default \n",
    "# Setting index to a unique identifier (like email) allows better use of loc. Instead of using index, we can use the specific value of the key that corresponds to the row as its identifier; people_df.loc['Soputan'] will locate Cherryl's row\n",
    "# During df initialization and data read, the index can be modified to a specified column using index_col; df = pd.read_csv('data.csv', index_col='EmployeeID')\n",
    "# sort_index(inplace=True) sorts the index alphabetically\n",
    "# inplace=True makes the change permanent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2528c135-9138-4232-9e05-7632ab0d049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTERS\n",
    "# == will output a boolean table depending on whether or not each row meets the given criteria; people_df['age'] == 18 will give True for the row with age = 18 and False otherwise\n",
    "# Assigning filter to a variable and passing it in a bracket notation to dataframe will fetch all the rows that meets the filter's criteria:\n",
    "# min_age_filt = (people_df['age'] == 18); people_df[min_age_filt] filters age 18\n",
    "# filter can also be passed to loc; people_df.loc[min_age_filt, 'first'] grabs a specific column (first) given the filter\n",
    "# in pandas conditional synatx, & is and | is or; filt = (df['age'] >= 18) & (df['first'][0] == 'c') \n",
    "\n",
    "#Example of filter\n",
    "#filt = ((people_df['age'] >= 18) & (people_df['gender'] == 'F')) | ((people_df['age'] > 18) & (people_df['gender'] == 'M')) # A compounded conditional filter example\n",
    "# ~ is a negation that fetches the complement of the result of the filter (everything else that doesn't match the filter)\n",
    "# use .str to convert things into string from dataframe type\n",
    "\n",
    "# EXAMPLE APPLICATION\n",
    "# salary_filt = (df['ConvertedComp'] ? 100000) & (df['Country'] == 'Indonesia')\n",
    "# df.loc[salary_filt, 'Country'].value_counts()\n",
    "# The snippet code above filters the amount of Indonesians software engineer who is compensated above 100,000 USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ddf27-aca5-4584-aa0f-0ebf475c4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATING DATA\n",
    "\n",
    "# Column names can be changed by direct assignment: df.columns = df.columns.str.replace('_', ' ') replaces _ to space for every single column name\n",
    "# .rename allows renaming individual columns: df.rename(columns={'first' : 'firstname', 'last' : 'last_name'}, inplace=True)\n",
    "# To replace data in a row, simply select the target row and column then use assignment operator : people_df.loc[0, ['firstname', 'lastname']] = ['John', 'Doe']. Can also pass a list to change the value of row but just select the row\n",
    "# apply allows passing of function to dataframe; people_df['first'].apply(len) checks length of first name in each row\n",
    "# applymap applies the function to individual values in the dataframe: people_df.applymap(len) calculates the length of every single row-column combination in the dataframe\n",
    "# replace({}) allows mapping of value: people_df['last'] = people_df['last'].replace({'Finn' : 'Iurii', 'Iurii' : 'Finn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93fc567c-3040-4484-b96c-79ba11efc8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETING AND ADDING\n",
    "# Creating a new column can be achieved by simply assigning columns which does not exist yet; people_df['fullname'] = people_df['first'] + ' ' + people_df['last'] creates a column called fullname that combines first and ast\n",
    "# .drop(columns=[x]) drops the column(s) x in a dataframe; people_df.drop(columns=[['fullname', 'gender']], inplace=True) drops the fullname and gender column\n",
    "# To split a column into 2 different columns: people_df[['first', 'last']] = people_df['fullname'].str.split(' ', expand=True)\n",
    "# ._append allows insertion of a row; people_df = people_df._append({'first' : 'Keilani'}, ignore_index=True)\n",
    "# ._append also can append dataframe given sort parameter; people_df = people_df._append(people_df2, ignore_index=True, sort=False)\n",
    "# Dropping rows also uses .drop but with index as its parameter; people_df.drop(index=1, inplace=True) drops the second row\n",
    "# Dropping rows can also be combined with filter and conditionals; people_df.drop(index=people_df[people_df['first'].str[0] == 'C'].index, inplace=True)\n",
    "# .concat() allows the creation of new dataframe by concatenating 2 different series; people_df_concat = pd.concat([df1, df2], axis='columns', sort=False) --> Concatenates by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "18b19c01-9622-4aa0-bac9-b0dc4b6cb85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SORTING\n",
    "# sort_values(by=x) sorts the row according to x; people_df.sort_values(by=['last', 'first'], ascending=[False, False], inplace=True) sorts the row by last and then first name in descending alphabetical order\n",
    "# sort_index() sorts the dataframe rows by its indices\n",
    "# Series can also be sorted with methods above\n",
    "# nlargest(x, y) fetches the x largest value rows in the column y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0f76c813-c73f-4506-bc32-4c2c9c7d0080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPING AND AGGREGATING\n",
    "# .mean(), .median(), and .mode() finds the mean, median, and mode of the series respectively; people_df['age'].median()\n",
    "# .describe() gives descriptive statistic for the entire dataframe, can also be ran on a series; df.describe()\n",
    "# .count() shows how many people responds while value_count() gives the frequency of each unique response. The parameter normalize in value_counts() will give percentage; df['SocialMedia'].value_counts(normalize=True)\n",
    "# .groupby() allows grouping of dataframe by certain columns. It will return a pandas GroupByDataFrame object; country_grp = df.groupby(['Country'])\n",
    "# .get_group() can be used for GBDF object to get a grouped dataframe based off the given condition; country_grp.get_group('United States')\n",
    "# .agg() function will give a dataframe given the list of function passed in; country_grp['ConvertedComp'].agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8e51a961-d14b-4de3-a439-710e42babdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANING DATA\n",
    "# .dropna(axis='index', how='any') will drop row if it has missing value if axis is sets to index and will drop column if it has missing value (either how=any or how=all) if axis is sets to column\n",
    "    # subset parameter allows more specific rows drop given specific column(s); people_df.dropna(axis='index', how='any', subset=['email'. 'last'], inplace=True) drops all rows without last or email, changing it to how=all will drop if both are N/A\n",
    "# Custom \"missing\" value can be replaced with pd.nan; df.replace('NA', pd.nan, inplace=True)\n",
    "# .isna() is a function that creates a dataframe mapping that shows which rows and columns are of NA value\n",
    "# .fillna(x) fills the NA values with x\n",
    "# .dtypes will show all the datatypes in datafrae\n",
    "# .astype(float/int) converts string to integer/float; df['age'] = df['age'].astype(float/int)\n",
    "# .unique() gives a list of unique values in given column; df['YearsCode'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19d62d2-0e70-406c-a441-98f03fab60be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "16baa831-91f4-41b8-a70d-995c6d2c4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING AND WRITING DATA \n",
    "\n",
    "# CSV AND TSV\n",
    "\n",
    "# .to_csv('savepath/data.csv') saves the dataframe to csv file\n",
    "# .to_csv('savepath/data.tsv', sep='\\t' saves the dataframe as a tab seperated value\n",
    "\n",
    "# EXCEL\n",
    "\n",
    "# install xlwt, openpyxl, and xlrd packages and do .to_excel('data/data.xlsx') to convert to excel\n",
    "# .read_excel('excel.xlsx') creates a dataframe based on excel file format\n",
    "\n",
    "#JSON\n",
    "\n",
    "# .to_json('data.json') saves data as json\n",
    "# .read_json('data.json') creates a dataframe based on json file format\n",
    "\n",
    "#SQL \n",
    "\n",
    "# install SQLAlchemy and psycopg2-binary to do SQL read and write\n",
    "# from sqlalchemy import create_engine; import pyscopg2\n",
    "# Create database connection: engine = create_engine('postgresql://dbuser:dbpass@localhost:5432/sample_db') creates a database called sample_db\n",
    "# .to_sql('sample_table', engine, if_exists=replace); to_sql is a function that creates a new table in sql given table's name and database engine connection\n",
    "# pd.read_sql(tablename, engine) creates a dataframe based off given SQL parameter. Can also use SQL Queries in the place of tablename\n",
    "\n",
    "# Datas can also be loaded from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300fbbb-a464-446c-95b7-468736981006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1845b471-ce9c-4fc2-abcb-8da10c53bcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb2f01-3901-4dfe-998c-98c81cdc1330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488acd76-b018-4ae1-89ec-0e9c6c6cd130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b3174-a3f1-4aef-9f75-65bdd5dea5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151348a-e945-4ca4-bdb4-e25af85b931f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3976cae-c93c-417a-b2f7-15a6893a13e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c88a35-c8ac-4a8f-9e78-15f29dd213b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25f873-43ab-4b37-9edd-ce9c21eddbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a1b28-9cff-4e4a-b2e8-5045cf177dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
